# ğŸ§  Sketch-to-Image Translation using CycleGAN & Pix2Pix

A Deep Learning project aimed at translating sketches into photorealistic images using two powerful GAN architectures â€” CycleGAN (for unpaired datasets) and Pix2Pix (for paired datasets). This project demonstrates the effectiveness of GANs in fashion design visualization and face reconstruction from sketch inputs.

## ğŸ‘¨â€ğŸ’» Team Members
- Manjur Kovadiya
- Rushiraj Jadeja
- Vandan Patel

---

## ğŸ¯ Objective

- Translate raw sketches into realistic images for fashion and facial datasets.
- Compare the performance of CycleGAN and Pix2Pix on unpaired vs paired datasets.
- Visualize improvements over training using loss plots and output snapshots.

---

## ğŸ“¦ Dataset Overview

### Fashion Dataset:
- Contains *paired* and *unpaired* sketch-real image sets.
- Images resized to **256x256** pixels.
- Split into `train/val` folders.

### Face Dataset:
- Contains *paired* sketch-real image sets.
- Stored in a single folder.
- Images resized to **256x256** pixels.

---

## ğŸ”§ Model Architectures

### CycleGAN
- 2 Generators: `G_Sâ†’R`, `G_Râ†’S`
- 2 Discriminators: `D_S`, `D_R`
- Losses: **Adversarial + Cycle-Consistency + Identity**
- Suitable for **unpaired** data

### Pix2Pix
- Single Generator and Discriminator
- Requires **paired** images
- Uses **U-Net** architecture and PatchGAN

---

## ğŸ§ª Training Details

- **Optimizer**: Adam (lr=0.0001, Î²1=0.5, Î²2=0.999)
- **Loss Functions**: MSE, L1
- **Early Stopping**: Enabled for stability
- **Output Generation**: Every 5 epochs
- **Replay Buffer**: Used in Discriminator training to reduce oscillations

---
